{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10975\n"
     ]
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "import re\n",
    "\n",
    "from utils import f1, text_to_wordlist, user_id\n",
    "from utils import clean_reaction, sub_user, encoder_predict, user_dict, channel_mapping\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# main message store\n",
    "with open('input_data/dan_bot_messages.pkl', 'rb') as f:\n",
    "    message_list, _ = pickle.load(f)\n",
    "    print(len(message_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'U9BT72G5T|tristan.findlay'\n",
      "'U029T9GDF|brendon'\n",
      "(7841, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>comment</th>\n",
       "      <th>emoji</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7838</th>\n",
       "      <td>tech_articles</td>\n",
       "      <td>&lt;http    lifepluslinux blogspot co za 2017 01 ...</td>\n",
       "      <td>amasin</td>\n",
       "      <td>2017-01-26 12:58:05.000271082</td>\n",
       "      <td>message</td>\n",
       "      <td>kingori</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7839</th>\n",
       "      <td>blockers</td>\n",
       "      <td>i threw my laptop out the window  got a new on...</td>\n",
       "      <td>joy</td>\n",
       "      <td>2017-01-26 11:40:05.000296116</td>\n",
       "      <td>message</td>\n",
       "      <td>brendon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7840</th>\n",
       "      <td>blockers</td>\n",
       "      <td>i threw my laptop out the window  got a new on...</td>\n",
       "      <td>raised_hands</td>\n",
       "      <td>2017-01-26 11:40:05.000296116</td>\n",
       "      <td>message</td>\n",
       "      <td>brendon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7841</th>\n",
       "      <td>london</td>\n",
       "      <td>the physicists will fight dirty</td>\n",
       "      <td>fire</td>\n",
       "      <td>2017-01-25 17:15:09.002577066</td>\n",
       "      <td>message</td>\n",
       "      <td>helen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7842</th>\n",
       "      <td>london</td>\n",
       "      <td>the physicists will fight dirty</td>\n",
       "      <td>gun</td>\n",
       "      <td>2017-01-25 17:15:09.002577066</td>\n",
       "      <td>message</td>\n",
       "      <td>helen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            channel                                            comment  \\\n",
       "7838  tech_articles  <http    lifepluslinux blogspot co za 2017 01 ...   \n",
       "7839       blockers  i threw my laptop out the window  got a new on...   \n",
       "7840       blockers  i threw my laptop out the window  got a new on...   \n",
       "7841         london                    the physicists will fight dirty   \n",
       "7842         london                    the physicists will fight dirty   \n",
       "\n",
       "             emoji                          time     type     user  \n",
       "7838        amasin 2017-01-26 12:58:05.000271082  message  kingori  \n",
       "7839           joy 2017-01-26 11:40:05.000296116  message  brendon  \n",
       "7840  raised_hands 2017-01-26 11:40:05.000296116  message  brendon  \n",
       "7841          fire 2017-01-25 17:15:09.002577066  message    helen  \n",
       "7842           gun 2017-01-25 17:15:09.002577066  message    helen  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store = {}\n",
    "emoji_count = defaultdict(int)\n",
    "\n",
    "for msg in message_list:\n",
    "    try:\n",
    "        if 'message' in msg:\n",
    "            msg_type, msg_info, channel = itemgetter('type', 'message', 'channel')(msg)\n",
    "            msg_info_type, msg_text, msg_reactions, msg_time = itemgetter('type', 'text', 'reactions', 'ts')(msg['message'])\n",
    "            if 'message' in msg and msg_text.strip != '':\n",
    "                msg_text = sub_user(msg_text)\n",
    "                clean_msg = text_to_wordlist(msg_text)\n",
    "                store[clean_msg] = {}\n",
    "                store[clean_msg]['reactions'] = [clean_reaction(reaction['name']) for reaction in msg_reactions if user_id in reaction['users'] ]\n",
    "                store[clean_msg]['time'] = msg_time\n",
    "                store[clean_msg]['type'] = 'message'\n",
    "                store[clean_msg]['joined_reactions'] = '|'.join(store[clean_msg]['reactions'])\n",
    "                store[clean_msg]['channel'] = channel\n",
    "                store[clean_msg]['type'] = msg['type']\n",
    "                if 'user' in msg['message']:\n",
    "                    store[clean_msg]['user'] = msg['message']['user']\n",
    "                elif 'bot_id' in msg['message']:\n",
    "                    store[clean_msg]['user'] = msg['message']['bot_id']\n",
    "                for emoji in store[clean_msg]:\n",
    "                    emoji_count[emoji] += 1\n",
    "        elif 'file' in msg:\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "long_store = []\n",
    "for k, v in store.items():\n",
    "    for reaction in v['reactions']:\n",
    "        long_store.append(\n",
    "            {'comment': k,\n",
    "             'emoji': reaction, \n",
    "             'channel': channel_mapping.get(v['channel'], 'private'), \n",
    "             'time': float(v['time']),\n",
    "             'user': user_dict.get(v.get('user', 'None'), 'bot'),\n",
    "             'type': v['type']\n",
    "            }\n",
    "        )\n",
    "        \n",
    "long_data = pd.DataFrame(long_store)\n",
    "long_data['time'] =  pd.to_datetime(long_data['time'],unit='s')\n",
    "long_data = long_data[long_data['time'].dt.year > 2016]\n",
    "\n",
    "print(long_data.shape)\n",
    "long_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba92a84ef4bb46efb4945eab03dee942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "w=widgets.Dropdown(\n",
    "    options=long_data['channel'].unique().tolist() + ['all'],\n",
    "    value='all',\n",
    "    description='Channel:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "def my_plot(w):\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    tmp = long_data if w == 'all' else long_data[long_data['channel'] == w]\n",
    "    tmp.groupby('emoji').count()['time'].rename('count').sort_values(ascending=False).head(35).plot(grid=True, ax=ax, kind='bar');\n",
    "    ax.set_title('Emoji counts for channel: %s' % w);\n",
    "    plt.show()\n",
    "\n",
    "interactive_plot = interactive(my_plot, w=w)\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872090ddfc444adda8a73b83fc0c153c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "w=widgets.Dropdown(\n",
    "    options=long_data['emoji'].unique().tolist() + ['all'],\n",
    "    value='all',\n",
    "    description='Emoji:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "def my_plot(w):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    tmp = long_data if w == 'all' else long_data[long_data['emoji'] == w]\n",
    "    tmp.groupby(pd.Grouper(key='time', freq='M')).count()['emoji'].rolling(2).mean().plot(grid=True, color = 'b');\n",
    "    ax.set_title('Emoji Count Over Time');\n",
    "    plt.show()\n",
    "\n",
    "interactive_plot = interactive(my_plot, w=w)\n",
    "interactive_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filering comments with most commonn emojis, down to  (5374, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emoji</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>+1</th>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_story</th>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notsureif</th>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>squanchy</th>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amasin</th>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trophy</th>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facepalm</th>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            comment\n",
       "emoji              \n",
       "joy             840\n",
       "+1              566\n",
       "true_story      450\n",
       "fire            324\n",
       "notsureif       279\n",
       "squanchy        188\n",
       "amasin          167\n",
       "trophy          141\n",
       "facepalm        134\n",
       "100             132"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg = long_data.groupby('emoji').count()['comment']\n",
    "\n",
    "emoji_counts = pd.DataFrame(agg.sort_values(ascending=False))\n",
    "filtered_emojis = emoji_counts[emoji_counts['comment'] > 20]\n",
    "df = long_data[long_data['emoji'].isin(filtered_emojis.index)]\n",
    "print('filering comments with most commonn emojis, down to ', df.shape)\n",
    "filtered_emojis.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4633, 66)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>time</th>\n",
       "      <th>channel</th>\n",
       "      <th>type</th>\n",
       "      <th>user</th>\n",
       "      <th>emoji_+1</th>\n",
       "      <th>emoji_100</th>\n",
       "      <th>emoji_amasin</th>\n",
       "      <th>emoji_beers</th>\n",
       "      <th>emoji_brendan</th>\n",
       "      <th>...</th>\n",
       "      <th>emoji_tinfoilhat</th>\n",
       "      <th>emoji_trollface</th>\n",
       "      <th>emoji_trophy</th>\n",
       "      <th>emoji_true_story</th>\n",
       "      <th>emoji_trump</th>\n",
       "      <th>emoji_wat</th>\n",
       "      <th>emoji_watchout_badass</th>\n",
       "      <th>emoji_whip</th>\n",
       "      <th>emoji_wow</th>\n",
       "      <th>emoji_wow_savage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2017-04-03 09:01:27.502793073</td>\n",
       "      <td>general</td>\n",
       "      <td>message</td>\n",
       "      <td>tommy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thinking that one above t...</td>\n",
       "      <td>2018-10-22 12:50:34.000099897</td>\n",
       "      <td>productowners</td>\n",
       "      <td>message</td>\n",
       "      <td>sam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>2018-06-06 09:06:01.000616074</td>\n",
       "      <td>random</td>\n",
       "      <td>message</td>\n",
       "      <td>stuart</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1  pry main  gt; x  =   a   2  b    c   3 ...</td>\n",
       "      <td>2017-03-28 13:26:11.006568909</td>\n",
       "      <td>tricks_of_the_trade</td>\n",
       "      <td>message</td>\n",
       "      <td>thom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>begin if stevebissett  =  =  nil raise arg...</td>\n",
       "      <td>2017-05-22 10:59:04.779649973</td>\n",
       "      <td>capetown</td>\n",
       "      <td>message</td>\n",
       "      <td>eliza</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  \\\n",
       "0                                                      \n",
       "1                       thinking that one above t...   \n",
       "2                                               yes    \n",
       "3      1  pry main  gt; x  =   a   2  b    c   3 ...   \n",
       "4      begin if stevebissett  =  =  nil raise arg...   \n",
       "\n",
       "                           time              channel     type    user  \\\n",
       "0 2017-04-03 09:01:27.502793073              general  message   tommy   \n",
       "1 2018-10-22 12:50:34.000099897        productowners  message     sam   \n",
       "2 2018-06-06 09:06:01.000616074               random  message  stuart   \n",
       "3 2017-03-28 13:26:11.006568909  tricks_of_the_trade  message    thom   \n",
       "4 2017-05-22 10:59:04.779649973             capetown  message   eliza   \n",
       "\n",
       "   emoji_+1  emoji_100  emoji_amasin  emoji_beers  emoji_brendan  ...  \\\n",
       "0         0          0             0            0              0  ...   \n",
       "1         0          0             0            0              0  ...   \n",
       "2         1          0             0            0              0  ...   \n",
       "3         0          0             0            0              0  ...   \n",
       "4         0          0             0            0              0  ...   \n",
       "\n",
       "   emoji_tinfoilhat  emoji_trollface  emoji_trophy  emoji_true_story  \\\n",
       "0                 0                0             0                 1   \n",
       "1                 0                0             0                 0   \n",
       "2                 0                0             0                 0   \n",
       "3                 0                0             1                 0   \n",
       "4                 0                0             0                 0   \n",
       "\n",
       "   emoji_trump  emoji_wat  emoji_watchout_badass  emoji_whip  emoji_wow  \\\n",
       "0            0          0                      0           0          0   \n",
       "1            0          0                      0           0          0   \n",
       "2            0          0                      0           0          0   \n",
       "3            0          0                      0           0          0   \n",
       "4            0          0                      0           0          0   \n",
       "\n",
       "   emoji_wow_savage  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_table = pd.get_dummies(df, columns = ['emoji']).groupby(['comment', 'time', 'channel', 'type', 'user']).sum().reset_index()\n",
    "print(formatted_table.shape)\n",
    "formatted_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4633, 1)\n",
      "(4633, 8594) (4633, 61)\n",
      "(3706, 8594) (3706, 61)\n",
      "(927, 8594) (927, 61)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import keras\n",
    "from utils import f1\n",
    "\n",
    "channel_encoder = OneHotEncoder()\n",
    "user_encoder = OneHotEncoder()\n",
    "\n",
    "one_hot_channels = channel_encoder.fit_transform(formatted_table['channel'].values.reshape(-1, 1))\n",
    "one_hot_users = user_encoder.fit_transform(formatted_table['user'].values.reshape(-1, 1))\n",
    "\n",
    "max_words = 10000\n",
    "\n",
    "# TF IDF\n",
    "vectorizer = TfidfVectorizer(max_features = max_words)\n",
    "X = vectorizer.fit_transform(formatted_table.comment.tolist())\n",
    "\n",
    "# Sentiment feature\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "sentiment = formatted_table.comment.apply(lambda x: analyser.polarity_scores(x)['compound']).values.reshape(-1, 1)\n",
    "print(sentiment.shape)\n",
    "\n",
    "# Channel feature\n",
    "channel_encoder = OneHotEncoder()\n",
    "one_hot_channels = channel_encoder.fit_transform(formatted_table['channel'].values.reshape(-1, 1))\n",
    "\n",
    "# User feature\n",
    "user_encoder = OneHotEncoder()\n",
    "one_hot_users = user_encoder.fit_transform(formatted_table['user'].values.reshape(-1, 1))\n",
    "\n",
    "# Concat features & split train/test\n",
    "X = np.concatenate((X.toarray(), sentiment, one_hot_channels.toarray(), one_hot_users.toarray()), axis=1)\n",
    "y_cols = [i for i in formatted_table.columns if 'emoji' in i]\n",
    "Y = formatted_table[y_cols]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=1000)\n",
    "print(Xtrain.shape, Ytrain.shape)\n",
    "print(Xtest.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 512)               4400640   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 61)                31293     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 61)                0         \n",
      "=================================================================\n",
      "Total params: 4,431,933\n",
      "Trainable params: 4,431,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3706 samples, validate on 927 samples\n",
      "Epoch 1/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 4.2004 - acc: 0.1730 - f1: 4.9341e-04 - val_loss: 3.7437 - val_acc: 0.2330 - val_f1: 0.0054\n",
      "Epoch 2/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 3.6177 - acc: 0.2380 - f1: 0.0259 - val_loss: 3.6264 - val_acc: 0.2384 - val_f1: 0.0235\n",
      "Epoch 3/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 3.0909 - acc: 0.3408 - f1: 0.1021 - val_loss: 3.5603 - val_acc: 0.2427 - val_f1: 0.0639\n",
      "Epoch 4/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 2.4624 - acc: 0.4949 - f1: 0.2344 - val_loss: 3.5548 - val_acc: 0.2287 - val_f1: 0.0828\n",
      "Epoch 5/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 1.8340 - acc: 0.6519 - f1: 0.4340 - val_loss: 3.6248 - val_acc: 0.1953 - val_f1: 0.0834\n",
      "Epoch 6/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 1.3157 - acc: 0.7863 - f1: 0.5931 - val_loss: 3.7071 - val_acc: 0.2050 - val_f1: 0.0994\n",
      "Epoch 7/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 0.9562 - acc: 0.8567 - f1: 0.7219 - val_loss: 3.8111 - val_acc: 0.1963 - val_f1: 0.1224\n",
      "Epoch 8/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 0.7307 - acc: 0.8899 - f1: 0.8023 - val_loss: 3.9053 - val_acc: 0.2060 - val_f1: 0.1355\n",
      "Epoch 9/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 0.6013 - acc: 0.9142 - f1: 0.8502 - val_loss: 4.0020 - val_acc: 0.1953 - val_f1: 0.1418\n",
      "Epoch 10/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 0.5144 - acc: 0.9185 - f1: 0.8770 - val_loss: 4.0892 - val_acc: 0.2060 - val_f1: 0.1594\n",
      "Epoch 11/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 0.4705 - acc: 0.9209 - f1: 0.8907 - val_loss: 4.1566 - val_acc: 0.2114 - val_f1: 0.1641\n",
      "Epoch 12/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 0.4398 - acc: 0.9290 - f1: 0.9001 - val_loss: 4.2270 - val_acc: 0.1953 - val_f1: 0.1552\n",
      "Epoch 13/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 0.4177 - acc: 0.9280 - f1: 0.9067 - val_loss: 4.3038 - val_acc: 0.1985 - val_f1: 0.1664\n",
      "Epoch 14/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 0.4018 - acc: 0.9312 - f1: 0.9106 - val_loss: 4.3653 - val_acc: 0.2104 - val_f1: 0.1755\n",
      "Epoch 15/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 0.3929 - acc: 0.9301 - f1: 0.9101 - val_loss: 4.3849 - val_acc: 0.1985 - val_f1: 0.1629\n",
      "Epoch 16/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 0.3868 - acc: 0.9242 - f1: 0.9123 - val_loss: 4.4376 - val_acc: 0.2147 - val_f1: 0.1838\n",
      "Epoch 17/25\n",
      "3706/3706 [==============================] - 6s 2ms/step - loss: 0.3718 - acc: 0.9334 - f1: 0.9130 - val_loss: 4.4967 - val_acc: 0.2114 - val_f1: 0.1777\n",
      "Epoch 18/25\n",
      "3706/3706 [==============================] - 6s 2ms/step - loss: 0.3709 - acc: 0.9296 - f1: 0.9140 - val_loss: 4.4885 - val_acc: 0.1963 - val_f1: 0.1680\n",
      "Epoch 19/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 0.3707 - acc: 0.9301 - f1: 0.9168 - val_loss: 4.5531 - val_acc: 0.2006 - val_f1: 0.1751\n",
      "Epoch 20/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 0.3673 - acc: 0.9334 - f1: 0.9148 - val_loss: 4.5752 - val_acc: 0.2082 - val_f1: 0.1872\n",
      "Epoch 21/25\n",
      "3706/3706 [==============================] - 6s 2ms/step - loss: 0.3606 - acc: 0.9301 - f1: 0.9162 - val_loss: 4.5942 - val_acc: 0.2114 - val_f1: 0.1895\n",
      "Epoch 22/25\n",
      "3706/3706 [==============================] - 6s 2ms/step - loss: 0.3562 - acc: 0.9307 - f1: 0.9153 - val_loss: 4.6273 - val_acc: 0.2039 - val_f1: 0.1807\n",
      "Epoch 23/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 0.3538 - acc: 0.9344 - f1: 0.9172 - val_loss: 4.6094 - val_acc: 0.2104 - val_f1: 0.1748\n",
      "Epoch 24/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 0.3560 - acc: 0.9317 - f1: 0.9180 - val_loss: 4.6566 - val_acc: 0.2136 - val_f1: 0.1885\n",
      "Epoch 25/25\n",
      "3706/3706 [==============================] - 7s 2ms/step - loss: 0.3505 - acc: 0.9304 - f1: 0.9176 - val_loss: 4.6478 - val_acc: 0.2104 - val_f1: 0.1814\n",
      "927/927 [==============================] - 0s 143us/step\n",
      "Test loss: 4.647822486029731\n",
      "Test accuracy: 0.2103559868942701\n",
      "Test F1 0.18142843088928806\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(Xtrain.shape[1],)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(Ytrain.shape[1]))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1])\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 25\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "history = model.fit(Xtrain, Ytrain, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    verbose=1, \n",
    "                    validation_data=(Xtest, Ytest), \n",
    "#                     callbacks=[early_stopping]\n",
    "                   )\n",
    "score = model.evaluate(Xtest, Ytest, batch_size=batch_size, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test F1', score[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brexit makes me sad -> joy\n",
      "great job on getting autocoding out, you massive nerds -> joy\n",
      "on leave that week -> +1\n",
      "production is down -> notsureif\n",
      "just be better -> true_story\n",
      "work harder -> joy\n",
      "rocket to production -> eggplant\n",
      "thats just wrong -> fire\n",
      "windows over mac -> wat\n",
      "you are a bell end -> fire\n",
      "it's not unreasonable to have a w9am meeting -> joy\n",
      "My understanding from talking to different folks is the issue is due to the different text length -> got_wood\n",
      "@steven.perianen IBM is loving the new verbatim auto coding! -> trophy\n",
      "heyhey @daniel.baark -> https://zigroup.atlassian.net/browse/SP-5320 -> +1\n",
      "The new DS review time clashes with another meeting -> joy\n",
      "It's not like me to skip meals -> got_wood\n",
      "There has been a complaint about people using the putney office and keeping the door propped open. Can people make sure the door isn't kept open when it shouldn't be. -> notsureif\n",
      "Ahh we call them a Microsoft Product Team -> joy\n"
     ]
    }
   ],
   "source": [
    "def process_pred(sentence, channel, user):\n",
    "    xpred = vectorizer.transform([sentence])\n",
    "    new_x = np.concatenate(\n",
    "        (\n",
    "            xpred.toarray(),\n",
    "            np.array([analyser.polarity_scores(sentence)\n",
    "                      ['compound']]).reshape(-1, 1),\n",
    "            encoder_predict(channel_encoder, channel).toarray(),\n",
    "            encoder_predict(user_encoder, user).toarray()\n",
    "        ), axis=1)\n",
    "    pred = model.predict(new_x)\n",
    "    return y_cols[np.argmax(pred)].split('emoji_')[-1]\n",
    "\n",
    "test_sentences = [\n",
    "    'brexit makes me sad',\n",
    "    'great job on getting autocoding out, you massive nerds',\n",
    "    'on leave that week', \n",
    "    'production is down', \n",
    "    'just be better', \n",
    "    'work harder', \n",
    "    'rocket to production', \n",
    "    'thats just wrong',\n",
    "    'windows over mac',\n",
    "    'you are a bell end',\n",
    "    \"it's not unreasonable to have a w9am meeting\",\n",
    "    \"My understanding from talking to different folks is the issue is due to the different text length\",\n",
    "    '@steven.perianen IBM is loving the new verbatim auto coding!',\n",
    "    'heyhey @daniel.baark -> https://zigroup.atlassian.net/browse/SP-5320',\n",
    "    \"The new DS review time clashes with another meeting\",\n",
    "    \"It's not like me to skip meals\",\n",
    "    \"There has been a complaint about people using the putney office and keeping the door propped open. Can people make sure the door isn't kept open when it shouldn't be.\",\n",
    "    \"Ahh we call them a Microsoft Product Team\"\n",
    "]\n",
    "\n",
    "for i, sent in enumerate(test_sentences):\n",
    "    print(sent, '->', process_pred(sent, 'london', 'fish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer, open(\"input_data/tfidf.pickle\", \"wb\"))\n",
    "pickle.dump(channel_encoder, open(\"input_data/channel_enc.pickle\", \"wb\"))\n",
    "pickle.dump(user_encoder, open(\"input_data/user_enc.pickle\", \"wb\"))\n",
    "pickle.dump(y_cols, open(\"input_data/y_cols.pickle\", \"wb\"))\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
